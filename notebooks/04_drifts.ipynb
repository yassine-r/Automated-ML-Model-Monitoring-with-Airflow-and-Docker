{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'preprocess' from 'd:\\\\projects\\\\get-me-a-fucking-job\\\\Automated ML Model Monitoring with Airflow and Docker\\\\dags\\\\src\\\\preprocess.py'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.ensemble import BaseEnsemble\n",
    "\n",
    "\n",
    "from deepchecks.tabular import Dataset\n",
    "from deepchecks.tabular import Suite\n",
    "from deepchecks.tabular.checks import WholeDatasetDrift, DataDuplicates, NewLabelTrainTest, TrainTestFeatureDrift, TrainTestLabelDrift\n",
    "from deepchecks.tabular.checks import FeatureLabelCorrelation, FeatureLabelCorrelationChange, ConflictingLabels, OutlierSampleDetection \n",
    "from deepchecks.tabular.checks import WeakSegmentsPerformance, RocReport, ConfusionMatrixReport, TrainTestPredictionDrift, CalibrationScore, BoostingOverfit\n",
    "\n",
    "import sys\n",
    "from importlib import reload\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'dags', 'src'))\n",
    "\n",
    "import helpers\n",
    "import config\n",
    "import preprocess\n",
    "\n",
    "\n",
    "reload(helpers)\n",
    "reload(config)\n",
    "reload(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_quality(df: pd.DataFrame, predictors: list[str], target: str, job_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Checks for data quality and saves a report in the results directory.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to check.\n",
    "        predictors (list[str]): Predictors to check for drifts.\n",
    "        target (str): Target variable to check for drifts.\n",
    "        job_id (str): Job ID.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing the report and the boolean result.\n",
    "    \"\"\"\n",
    "    # Filter features and categorical features based on the columns in the DataFrame\n",
    "    features = [col for col in predictors if col in df.columns]\n",
    "    cat_features = [col for col in config.CAT_VARS if col in df.columns]\n",
    "    \n",
    "    # Create a Dataset object with the filtered features and categorical features\n",
    "    dataset = Dataset(df, label=target, features=features, cat_features=cat_features, datetime_name=config.DATETIME_VARS[0])\n",
    "    \n",
    "    # Create a Suite object for data quality checks\n",
    "    data_quality_suite = Suite(\"data quality\",\n",
    "        DataDuplicates().add_condition_ratio_less_or_equal(0.3), #Checks for duplicate samples in the dataset\n",
    "        ConflictingLabels().add_condition_ratio_of_conflicting_labels_less_or_equal(0), #Find samples which have the exact same features' values but different labels\n",
    "        FeatureLabelCorrelation().add_condition_feature_pps_less_than(0.9), #Return the PPS (Predictive Power Score) of all features in relation to the label\n",
    "        OutlierSampleDetection(outlier_score_threshold=0.7).add_condition_outlier_ratio_less_or_equal(0.1), #Detects outliers in a dataset using the LoOP algorithm\n",
    "    )\n",
    "    \n",
    "    # Run the data quality suite on the dataset\n",
    "    report = data_quality_suite.run(dataset)\n",
    "    \n",
    "    try:\n",
    "        # Save the report as an HTML file\n",
    "        report_path = f\"{config.PATH_DIR_RESULTS}/reports/{job_id}_data_quality_report.html\"\n",
    "        report.save_as_html(report_path)\n",
    "        print(f\"[INFO] Data quality report saved as {report_path}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"[WARNING][DRIFTS.SKIP_TRAIN] {traceback.format_exc()}\")\n",
    "    \n",
    "    # Return the report and the boolean result\n",
    "    return {\"report\": report, \"retrain\": report.passed()}\n",
    "\n",
    "\n",
    "def check_data_drift(ref_df: pd.DataFrame, cur_df: pd.DataFrame, predictors: list[str], target: str, job_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Check for data drifts between two datasets and decide whether to retrain the model.\n",
    "    A report will be saved in the results directory.\n",
    "    \n",
    "    Args:\n",
    "        ref_df (pd.DataFrame): Reference dataset.\n",
    "        cur_df (pd.DataFrame): Current dataset.\n",
    "        predictors (list[str]): Predictors to check for drifts.\n",
    "        target (str): Target variable to check for drifts.\n",
    "        job_id (str): Job ID.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing the report and the boolean result.\n",
    "    \"\"\"\n",
    "    # Filter features and categorical features based on the columns in the DataFrames\n",
    "    ref_features = [col for col in predictors if col in ref_df.columns]\n",
    "    cur_features = [col for col in predictors if col in cur_df.columns]\n",
    "    ref_cat_features = [col for col in config.CAT_VARS if col in ref_df.columns]\n",
    "    cur_cat_features = [col for col in config.CAT_VARS if col in cur_df.columns]\n",
    "    \n",
    "    # Create Dataset objects for the reference and current datasets\n",
    "    ref_dataset = Dataset(ref_df, label=target, features=ref_features, cat_features=ref_cat_features, datetime_name=config.DATETIME_VARS[0])\n",
    "    cur_dataset = Dataset(cur_df, label=target, features=cur_features, cat_features=cur_cat_features, datetime_name=config.DATETIME_VARS[0])\n",
    "    \n",
    "    # Create a Suite object for data drift checks\n",
    "    data_drift_suite = Suite(\"data drift\",\n",
    "        NewLabelTrainTest(),\n",
    "        WholeDatasetDrift().add_condition_overall_drift_value_less_than(0.01), #0.2\n",
    "        FeatureLabelCorrelationChange().add_condition_feature_pps_difference_less_than(0.05), #0.2\n",
    "        TrainTestFeatureDrift().add_condition_drift_score_less_than(0.01), #0.1\n",
    "        TrainTestLabelDrift().add_condition_drift_score_less_than(0.01) #0.1\n",
    "    )\n",
    "    \n",
    "    # Run the data drift suite on the reference and current datasets\n",
    "    report = data_drift_suite.run(ref_dataset, cur_dataset)\n",
    "    \n",
    "    # Determine whether to retrain based on the results of the checks\n",
    "    retrain = (len(report.get_not_ran_checks()) > 0) or (len(report.get_not_passed_checks()) > 0)\n",
    "    \n",
    "    try:\n",
    "        # Save the report as an HTML file\n",
    "        report_path = f\"{config.PATH_DIR_RESULTS}/reports/{job_id}_data_drift_report.html\"\n",
    "        report.save_as_html(report_path)\n",
    "        print(f\"[INFO] Data drift report saved as {report_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING][DRIFTS.check_DATA_DRIFT] {traceback.format_exc()}\")\n",
    "    \n",
    "    # Return the report and the boolean result\n",
    "    return {\"report\": report, \"retrain\": retrain}\n",
    "\n",
    "\n",
    "def check_model_drift(ref_df: pd.DataFrame, cur_df: pd.DataFrame, model: BaseEnsemble, predictors: list[str], target: str, job_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Using the same pre-trained model, compare drifts in predictions between two datasets and decide whether to retrain the model.\n",
    "    A report will be saved in the results directory.\n",
    "    \n",
    "    Args:\n",
    "        ref_df (pd.DataFrame): Reference dataset.\n",
    "        cur_df (pd.DataFrame): Current dataset.\n",
    "        model (BaseEnsemble): Pre-trained model. Only scikit-learn and xgboost models are supported.\n",
    "        predictors (list[str]): Predictors to check for drifts.\n",
    "        target (str): Target variable to check for drifts.\n",
    "        job_id (str): Job ID.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing the report and the boolean result.\n",
    "    \"\"\"\n",
    "    # Filter features and categorical features based on the columns in the DataFrames\n",
    "    ref_features = [col for col in predictors if col in ref_df.columns]\n",
    "    cur_features = [col for col in predictors if col in cur_df.columns]\n",
    "    ref_cat_features = [col for col in config.CAT_VARS if col in ref_df.columns]\n",
    "    cur_cat_features = [col for col in config.CAT_VARS if col in cur_df.columns]\n",
    "    \n",
    "    # Create Dataset objects for the reference and current datasets\n",
    "    ref_dataset = Dataset(ref_df, label=target, features=ref_features, cat_features=ref_cat_features, datetime_name=config.DATETIME_VARS[0])\n",
    "    cur_dataset = Dataset(cur_df, label=target, features=cur_features, cat_features=cur_cat_features, datetime_name=config.DATETIME_VARS[0])\n",
    "    \n",
    "    # Create a Suite object for model drift checks\n",
    "    model_drift_suite = Suite(\"model drift\",\n",
    "        #For each class plots the ROC curve, calculate AUC score and displays the optimal threshold cutoff point.\n",
    "        RocReport().add_condition_auc_greater_than(0.7), \n",
    "        #Calculate prediction drift between train dataset and test dataset, Cramer's V for categorical output and Earth Movers Distance for numerical output.\n",
    "        TrainTestPredictionDrift().add_condition_drift_score_less_than(max_allowed_drift_score=0.1) \n",
    "        )\n",
    "    \n",
    "    # Run the model drift suite on the reference and current datasets using the pre-trained model\n",
    "    report = model_drift_suite.run(ref_dataset, cur_dataset, model)\n",
    "    \n",
    "    # Determine whether to retrain based on the results of the checks\n",
    "    retrain = (len(report.get_not_ran_checks()) > 0) or (len(report.get_not_passed_checks()) > 0)\n",
    "    \n",
    "    try:\n",
    "        # Save the report as an HTML file\n",
    "        report_path = f\"{config.PATH_DIR_RESULTS}/reports/{job_id}_model_drift_report.html\"\n",
    "        report.save_as_html(report_path)\n",
    "        print(f\"[INFO] Model drift report saved as {report_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING][DRIFTS.check_MODEL_DRIFT] {traceback.format_exc()}\")\n",
    "    \n",
    "    # Return the report and the boolean result\n",
    "    return {\"report\": report, \"retrain\": retrain}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id1 = \"04782775f4d4426f8b5256546c1e2960\"\n",
    "job_id2 = \"736cd81b1aad420fb74083c18546fca7\" \n",
    "\n",
    "filename1 = f\"../dags/data/collected/{job_id1}.csv\"\n",
    "filename2 = f\"../dags/data/collected/{job_id2}.csv\"\n",
    "\n",
    "df1 = pd.read_csv(filename1)\n",
    "df2 = pd.read_csv(filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Converting purpose to int using method: weighted ranking\n",
      "[INFO] No model for purpose-to-int conversion provided. Training a new model first...\n",
      "[INFO] Model saved as json file: ../dags/models\\04782775f4d4426f8b5256546c1e2960_purpose_to_int_model.json\n",
      "[INFO] Model loaded: 04782775f4d4426f8b5256546c1e2960_missing_values_model\n",
      "[INFO] Dataset saved to ../dags/data\\preprocessed\\736cd81b1aad420fb74083c18546fca7_inference.csv\n"
     ]
    }
   ],
   "source": [
    "tdf1 = pd.read_csv(f\"../dags/data/preprocessed/{job_id1}_training.csv\")\n",
    "vdf1 = pd.read_csv(f\"../dags/data/preprocessed/{job_id1}_inference.csv\")\n",
    "vdf2 = preprocess.preprocess_data(df=df2, mode=\"inference\", job_id=job_id2, rescale=False, ref_job_id=job_id1)\n",
    "\n",
    "\n",
    "deploy_report = json.load(open(f\"../dags/models/deploy_report.json\", \"r\"))\n",
    "pred_model = pickle.load(open(f\"../dags/models/{deploy_report['prediction_model']}\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Data quality report saved as ../dags/results/reports/04782775f4d4426f8b5256546c1e2960_data_quality_report.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Data quality report saved as ../dags/results/reports/736cd81b1aad420fb74083c18546fca7_data_quality_report.html\n"
     ]
    }
   ],
   "source": [
    "dq_chk1 = check_data_quality(df1, predictors=config.PREDICTORS, target=config.TARGET, job_id=job_id1)\n",
    "dq_chk2 = check_data_quality(df2, predictors=config.PREDICTORS, target=config.TARGET, job_id=job_id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Data drift report saved as ../dags/results/reports/736cd81b1aad420fb74083c18546fca7_data_drift_report.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Data drift report saved as ../dags/results/reports/736cd81b1aad420fb74083c18546fca7_b_data_drift_report.html\n"
     ]
    }
   ],
   "source": [
    "# compare raw data\n",
    "dd_1_2 = check_data_drift(ref_df=df1, cur_df=df2, predictors=config.PREDICTORS, target=config.TARGET, job_id=job_id2)\n",
    "\n",
    "# compare preprocessed datasets\n",
    "dd_1_2b = check_data_drift(ref_df=vdf1, cur_df=vdf2, predictors=config.PREDICTORS, target=config.TARGET, job_id=job_id2+\"_b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model drift report saved as ../dags/results/reports/736cd81b1aad420fb74083c18546fca7_model_drift_report.html\n"
     ]
    }
   ],
   "source": [
    "md_1_2 = check_model_drift(ref_df=vdf1, cur_df=vdf2, model=pred_model, predictors=config.PREDICTORS, target=config.TARGET, job_id=job_id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
