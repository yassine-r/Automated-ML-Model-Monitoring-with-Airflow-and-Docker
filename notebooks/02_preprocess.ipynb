{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'dags', 'src'))\n",
    "\n",
    "import config\n",
    "import helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = list(map(str.lower, config.CAT_VARS))\n",
    "num_vars = list(map(str.lower, config.NUM_VARS))\n",
    "date_vars = list(map(str.lower, config.DATETIME_VARS))\n",
    "exc_vars = list(map(str.lower, config.EXC_VARIABLES))\n",
    "engineered_vars = {\n",
    "    \"categorical\": [\"application_year\", \"application_month\", \"application_week\", \"application_day\", \"application_season\"],\n",
    "    \"numerical\": [\"current_credit_balance_ratio\"],\n",
    "    \"date\": [\"application_date\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables_with_missing_values(df: pd.DataFrame) -> list:\n",
    "    \"\"\"\n",
    "    Get variables with missing values.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of variables with missing values.\n",
    "    \"\"\"\n",
    "    # Calculate the count of missing values for each variable\n",
    "    missing_counts = df.isnull().sum()\n",
    "    \n",
    "    # Filter the variables with missing values and return as a list\n",
    "    variables_with_missing_values = missing_counts[missing_counts > 0].index.tolist()\n",
    "    \n",
    "    return variables_with_missing_values\n",
    "\n",
    "def impute_missing_values(df: pd.DataFrame, method: str = \"basic\", mode: str = None, cat_vars: list = cat_vars, num_vars: list = num_vars, job_id: str = \"\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Treat missing values.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        method (str): The imputation method to use. Default is \"basic\".\n",
    "        mode (str): The mode of operation, either \"training\" or \"inference\".\n",
    "        cat_vars (list): List of categorical variables. Default is cat_vars.\n",
    "        num_vars (list): List of numerical variables. Default is num_vars.\n",
    "        job_id (str): The job ID. Default is an empty string.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with imputed missing values.\n",
    "    \"\"\"\n",
    "    assert mode in (\"training\", \"inference\"), f\"mode must be either 'training' or 'inference', but got {mode}\"\n",
    "    assert method in [\"basic\", \"advanced\"], f\"{method} is not a valid method (basic, advanced)\"\n",
    "    \n",
    "    if mode == \"training\":\n",
    "        model = {\n",
    "            \"method\": method,\n",
    "            \"imputes\": dict()\n",
    "        }\n",
    "        \n",
    "        for col in df.columns:\n",
    "            print(\"[INFO] Treating missing values in column:\", col)\n",
    "            \n",
    "            model[\"imputes\"][col] = dict()\n",
    "            \n",
    "            if method == \"basic\":\n",
    "                if col in set(cat_vars + engineered_vars[\"categorical\"]):\n",
    "                    model[\"imputes\"][col]['mode'] = df[df[col].notnull()][col].mode()[0]\n",
    "                elif col in set(num_vars + engineered_vars[\"numerical\"]):\n",
    "                    model[\"imputes\"][col]['mean'] = df[df[col].notnull()][col].mean()\n",
    "                elif col in set(date_vars + engineered_vars[\"date\"]):\n",
    "                    model[\"imputes\"][col]['mode'] = df[df[col].notnull()][col].mode()[0]\n",
    "                elif col in [\"loan_id\", \"customer_id\", \"loan_status\"] + exc_vars:\n",
    "                    pass\n",
    "                else:\n",
    "                    raise ValueError(f\"[ERROR] {col} is not a valid variable\")\n",
    "            \n",
    "            if method == \"advanced\":\n",
    "                raise NotImplementedError\n",
    "        \n",
    "        helpers.save_model_as_pickle(model, f\"{job_id}_missing_values_model\")\n",
    "        return impute_missing_values(df, method=method, mode=\"inference\", cat_vars=cat_vars, num_vars=num_vars, job_id=job_id)\n",
    "    \n",
    "    else:\n",
    "        model = helpers.load_model_from_pickle(model_name=f\"{job_id}_missing_values_model\")\n",
    "        cols = get_variables_with_missing_values(df)\n",
    "        method = model[\"method\"]\n",
    "        \n",
    "        if method == \"basic\":\n",
    "            for col in cols:\n",
    "                if col in set(cat_vars + engineered_vars[\"categorical\"]):\n",
    "                    df[col].fillna(model[\"imputes\"][col]['mode'], inplace=True)\n",
    "                elif col in set(num_vars + engineered_vars[\"numerical\"]):\n",
    "                    df[col].fillna(model[\"imputes\"][col]['mean'], inplace=True)\n",
    "                elif col in set(date_vars + engineered_vars[\"date\"]):\n",
    "                    df[col].fillna(model[\"imputes\"][col]['mode'], inplace=True)\n",
    "                elif col in [\"loan_id\", \"customer_id\", \"loan_status\"] + exc_vars:\n",
    "                    pass\n",
    "                else:\n",
    "                    raise ValueError(f\"[ERROR] {col} is not a valid variable. Pre-trained variables: {list(model['imputes'].keys())}\")\n",
    "        \n",
    "        if method == \"advanced\":\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    return df\n",
    "\n",
    "## enforcing datatypes\n",
    "\n",
    "def enforce_numeric_to_float(x: str) -> float:\n",
    "    \"\"\"\n",
    "    Converts a string to a float, or returns `np.nan` if the string is not a valid float.\n",
    "\n",
    "    Parameters:\n",
    "        x: The string to be converted to a float.\n",
    "\n",
    "    Returns:\n",
    "        The float representation of the string, or `np.nan` if the string could not be converted to a float.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        return float(re.sub(\"[^0-9.]\",\"\", str(x)))\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "def enforce_datatypes(df: pd.DataFrame, cat_vars: list=cat_vars, num_vars: list=num_vars) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Enforces the data types of the columns in a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: The pandas DataFrame to be updated.\n",
    "        cat_vars: A list of the categorical variables in the DataFrame.\n",
    "        num_vars: A list of the numeric variables in the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        The pandas DataFrame with the enforced data types.\n",
    "    \"\"\"\n",
    "\n",
    "    df[\"application_time\"] = pd.to_datetime(df[\"application_time\"])\n",
    "    for var in num_vars:\n",
    "        df[var] = df[var].apply(lambda x: enforce_numeric_to_float(x))\n",
    "    for var in cat_vars:\n",
    "        df[var] = df[var].astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "## Encoding categorical features\n",
    "\n",
    "def categorize_years_in_current_job(x: str) -> int:\n",
    "    \"\"\"\n",
    "    Categorize years in current job into numerical values.\n",
    "    \n",
    "    Args:\n",
    "    x (str): The input string representing years in current job.\n",
    "    \n",
    "    Returns:\n",
    "    int: The categorized numerical value representing years in current job.\n",
    "    \"\"\"\n",
    "    x = str(x).strip()  # Clean up input by removing leading/trailing spaces\n",
    "    \n",
    "    if x == '< 1 year':\n",
    "        return 0  # Special case for less than 1 year\n",
    "    \n",
    "    if x in ('1 year', '2 years', '3 years', '4 years', '5 years', '6 years', '7 years', '8 years', '9 years', '10 years'):\n",
    "        return int(re.sub(\"[^0-9]\", \"\", x))  # Extract numerical value from the string\n",
    "    \n",
    "    if x == '10+ years':\n",
    "        return 11  # Special case for 10 or more years\n",
    "    \n",
    "    return -1  # Return -1 for unrecognized cases\n",
    "\n",
    "def term_to_int(x: str) -> int:\n",
    "    \"\"\"\n",
    "    Convert term (lowercased) to integer representation.\n",
    "    \n",
    "    Args:\n",
    "    x (str): Lowercased term (\"short term\" or \"long term\").\n",
    "    \n",
    "    Returns:\n",
    "    int: Integer representation of the term (0 for \"short term\", 1 for \"long term\"),\n",
    "    or np.nan for unrecognized cases.\n",
    "    \"\"\"\n",
    "    if x == \"short term\":\n",
    "        return 0\n",
    "    elif x == \"long term\":\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan  # Return np.nan for unrecognized cases\n",
    "\n",
    "def home_ownership_to_int(x: str) -> int:\n",
    "    \"\"\"\n",
    "    Convert home ownership (lowercased) to integer representation.\n",
    "    \n",
    "    Args:\n",
    "    x (str): Lowercased home ownership status.\n",
    "    \n",
    "    Returns:\n",
    "    int: Integer representation of home ownership\n",
    "    (0 for \"rent\", 1 for \"mortgage\", 2 for \"own\"),\n",
    "    or np.nan for unrecognized cases.\n",
    "    \"\"\"\n",
    "    if x == \"rent\":\n",
    "        return 0\n",
    "    elif \"home mortgage\" in x:\n",
    "        return 1\n",
    "    elif \"own home\" in x:\n",
    "        return 2\n",
    "    else:\n",
    "        return np.nan  # Return np.nan for unrecognized cases\n",
    "    \n",
    "\n",
    "def train_purpose_to_int_model(x: pd.Series, method: str, job_id: str = \"\") -> dict:\n",
    "    \"\"\"\n",
    "    Build a model file to be used to convert string variable `purpose` into integer datatype.\n",
    "    \n",
    "    Args:\n",
    "        x (pd.Series): The input series.\n",
    "        method (str): The method to use for conversion. Valid options are:\n",
    "            - \"ranking\": Replace each value by its rank based on frequency.\n",
    "            - \"relative ranking\": Replace each value by the ratio of its frequency to the highest frequency.\n",
    "            - \"weighted ranking\": Replace each value by the ratio of its frequency to the total number of values (or sum of frequencies).\n",
    "        job_id (str, optional): The job ID. Default is an empty string.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The purpose-to-int model.\n",
    "    \"\"\"\n",
    "    assert method in [\"ranking\", \"weighted ranking\", \"relative ranking\"], f\"{method} is not a valid methods (ranking, weighted ranking, relative ranking)\"\n",
    "    val_counts = x.value_counts()\n",
    "    if method==\"ranking\":\n",
    "        uniq_vals = sorted(val_counts.unique(), reverse=False)\n",
    "        val_to_int = dict(zip(uniq_vals, range(1, len(uniq_vals)+1)))\n",
    "        model = val_counts.apply(lambda x: val_to_int[x]).to_dict()\n",
    "        helpers.save_model_as_json(model, f\"{job_id}_purpose_to_int_model\")        \n",
    "        return model\n",
    "    if method==\"relative ranking\":\n",
    "        model = (val_counts/val_counts.max()).to_dict()\n",
    "        helpers.save_model_as_json(model, f\"{job_id}_purpose_to_int_model\")        \n",
    "        return model\n",
    "    if method==\"weighted ranking\":\n",
    "        model = (val_counts/val_counts.sum()).to_dict()\n",
    "        helpers.save_model_as_json(model, f\"{job_id}_purpose_to_int_model\")        \n",
    "        return model\n",
    "\n",
    "\n",
    "def purpose_to_int(x:pd.Series, mode:str, method:str=None, model:str=None, job_id:str=\"\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Convert purpose to int.\n",
    "    :param x:pd.Series\n",
    "    :param mode: str, choose from \"training\", \"inference\"\n",
    "    :param method: str, \"ranking\",  \"weighted ranking\", \"relative ranking\"\n",
    "        - ranking \n",
    "            rank values by their frequency and assign a rank to each value. The most frequent value will have the highest rank\n",
    "        - relative ranking\n",
    "            replace each value by the ratio of its frequency to the highest frequency\n",
    "        - weighted ranking\n",
    "            replace each value by the ratio of its frequency to the total number of values\n",
    "        when method is None and model is not None, any new value (not present in the model) will be encoded as 0\n",
    "    :param model: method, model to predict the purpose. If None, a new model will be trained and saved to the default directory of models as defined in the config file\n",
    "    :param save_report: bool, whether to save the report of missed/new values. Not implemented for nor\n",
    "    :param job_id: str, job id\n",
    "    :return:pd.Series\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Converting purpose to int using method:\", method)\n",
    "    \n",
    "    if model==None:\n",
    "        print(\"[INFO] No model for purpose-to-int conversion provided. Training a new model first...\")\n",
    "        mode = \"training\"\n",
    "    if mode==\"training\":\n",
    "        model = train_purpose_to_int_model(x, method, job_id=job_id)\n",
    "        # return purpose_to_int(x, method=method, model=model, job_id=job_id)\n",
    "        return x.apply(lambda x: model.get(x, 0))\n",
    "    else:\n",
    "        model = helpers.load_model_from_json(model_name=f\"{job_id}_purpose_to_int_model\")\n",
    "        return x.apply(lambda x: model.get(x, 0))\n",
    "    \n",
    "\n",
    "def loan_status_to_int(x: str) -> int:\n",
    "    \"\"\"\n",
    "    Convert loan status (lowercased) to integer representation.\n",
    "    \n",
    "    Args:\n",
    "    x (str): Lowercased loan status.\n",
    "    \n",
    "    Returns:\n",
    "    int: Integer representation of loan status\n",
    "    (0 for \"loan refused\", 1 for \"loan given\"),\n",
    "    or the input value itself if it's not recognized.\n",
    "    \"\"\"\n",
    "    valid_statuses = (\"loan given\", \"loan refused\")\n",
    "    assert x in valid_statuses or isinstance(x, int), f\"{x} is not a valid loan status and is not an integer\"\n",
    "    \n",
    "    x = str(x).strip()  # Clean up input by removing leading/trailing spaces\n",
    "    \n",
    "    if x == \"loan refused\":\n",
    "        return 0\n",
    "    if x == \"loan given\":\n",
    "        return 1\n",
    "    \n",
    "    return x  # Return the original value if it's not recognized as a valid loan status\n",
    "\n",
    "\n",
    "def encode_categorical_variables(df:pd.DataFrame, mode=\"training\", purpose_encode_method=\"ranking\", job_id:str=\"\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Encode categorical variables.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame\n",
    "        mode: str, \"training\" or \"inference\"\n",
    "        purpose_encode_method: str, choose from \"ranking\", \"weighted ranking\", \"relative ranking\"\n",
    "        job_id: str, job id\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "    assert mode in (\"training\", \"inference\"), f\"{mode} is not a valid mode (training , inference)\"\n",
    "    assert isinstance(job_id, str)\n",
    "    for col in cat_vars:\n",
    "        assert col in df.columns, f\"{col} not in {df.columns}\"\n",
    "        df[col] = df[col].str.lower()\n",
    "\n",
    "    df[\"term\"] = df[\"term\"].apply(lambda x: term_to_int(x))\n",
    "    df[\"home_ownership\"] = df[\"home_ownership\"].apply(lambda x: home_ownership_to_int(x))  \n",
    "    df[\"years_in_current_job\"] = df[\"years_in_current_job\"].apply(lambda x: categorize_years_in_current_job(x))\n",
    "    if config.TARGET.lower() in df.columns:\n",
    "        df[config.TARGET.lower()] = df[config.TARGET.lower()].apply(lambda x: loan_status_to_int(x))\n",
    "    df[\"purpose\"] = purpose_to_int(df[\"purpose\"], mode=mode, method=purpose_encode_method, job_id=job_id)\n",
    "    return df\n",
    "\n",
    "## features engineering\n",
    "\n",
    "def month_to_season(month: int) -> int:\n",
    "    \"\"\"\n",
    "    Convert month to season.\n",
    "    \n",
    "    Args:\n",
    "    month (int): The input month (1-12).\n",
    "    \n",
    "    Returns:\n",
    "    int: The corresponding season (1: Winter, 2: Spring, 3: Summer, 4: Fall).\n",
    "    If the input month is not in the valid range (1-12), returns -1 to indicate an error.\n",
    "    \"\"\"\n",
    "    if 1 <= month <= 3:\n",
    "        return 1  # Winter\n",
    "    elif 4 <= month <= 6:\n",
    "        return 2  # Spring\n",
    "    elif 7 <= month <= 9:\n",
    "        return 3  # Summer\n",
    "    elif 10 <= month <= 12:\n",
    "        return 4  # Fall\n",
    "    else:\n",
    "        return np.nan  # Invalid month\n",
    "    \n",
    "\n",
    "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Engineer new features based on the application_time column.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): The input DataFrame with application_time column.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with added engineered features.\n",
    "    \"\"\"\n",
    "    # Check if the necessary columns are present in the DataFrame\n",
    "    assert \"application_time\" in df.columns, f\"application_time not in {df.columns}\"\n",
    "    \n",
    "    # Extract date-based features from the application_time column\n",
    "    df[\"application_date\"] = df[\"application_time\"].dt.date\n",
    "    df[\"application_year\"] = df[\"application_time\"].dt.year\n",
    "    df[\"application_month\"] = df[\"application_time\"].dt.month\n",
    "    df[\"application_week\"] = df[\"application_time\"].dt.isocalendar().week  \n",
    "    df[\"application_day\"] = df[\"application_time\"].dt.day\n",
    "    \n",
    "    # Map application_month to application_season using month_to_season function\n",
    "    df[\"application_season\"] = df[\"application_month\"].apply(lambda x: month_to_season(x))\n",
    "    \n",
    "    # Calculate current_credit_balance_ratio while handling division by zero\n",
    "    df[\"current_credit_balance_ratio\"] = (df[\"current_credit_balance\"] / df[\"current_loan_amount\"]).fillna(0.0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "## data transformation\n",
    "\n",
    "def rescale_data(df:pd.DataFrame, method:str='standardize', mode:str='training', columns:list=[], job_id:str=\"\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Rescale data.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        method (str, optional): The rescaling method, either 'standardize' or 'minmax'. Default is 'standardize'.\n",
    "        mode (str, optional): The mode of operation, either 'training' or 'inference'. Default is 'training'.\n",
    "        columns (list, optional): The list of columns to rescale. Default is an empty list.\n",
    "        job_id (str, optional): The job ID. Default is an empty string.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The rescaled DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert method in ('standardize', 'minmax'), f\"{method} is not a valid method (standardize, minmax)\"\n",
    "    assert mode in ('training', 'inference'), f\"{mode} is not a valid mode (training, inference)\"\n",
    "    for col in columns:\n",
    "        assert col in df.columns\n",
    "\n",
    "    if mode=='training':\n",
    "        if method=='standardize':\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(df[columns])\n",
    "        if method=='minmax':\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(df[columns])\n",
    "        model = {\n",
    "            'scaler': scaler,\n",
    "            'method': method,\n",
    "        }\n",
    "\n",
    "        helpers.save_model_as_pickle(model, f\"{config.PATH_DIR_MODELS}/{job_id}_numerical_scaler.pkl\")\n",
    "        df[list(map(lambda x: f\"{method}_{x}\", columns))] = scaler.transform(df[columns])\n",
    "        return df\n",
    "    if mode=='inference':\n",
    "        model = helpers.load_model_from_pickle(model_name=f\"{job_id}_numerical_scaler.pkl\")\n",
    "        scaler = model['scaler']\n",
    "        method = model['method']\n",
    "        for col in columns:\n",
    "            try:\n",
    "                df[col].astype(float)\n",
    "            except:\n",
    "                print(\"[DEBUG] Column skipped:\", col)\n",
    "        df[list(map(lambda x: f\"{method}_{x}\", columns))] = scaler.transform(df[columns])\n",
    "        return df\n",
    "    \n",
    "## Preprocess\n",
    "def split_train_test(df:pd.DataFrame, test_size:float, method:str='time based'):\n",
    "    \"\"\"\n",
    "    Split data into train and test.\n",
    "    :param df: DataFrame\n",
    "    :param test_size: float, between 0 and 0.99\n",
    "    :param method: str, 'time based' or 'random'\n",
    "    :return: (DataFrame, DataFrame)\n",
    "    \"\"\"\n",
    "    if method=='random':\n",
    "        return df.sample(frac=1, random_state=config.RANDOM_STATE).iloc[:int(len(df)*test_size)], df.sample(frac=1, random_state=config.RANDOM_STATE).iloc[int(len(df)*test_size):]\n",
    "    if method=='time based':\n",
    "        unique_dates = sorted(df[\"application_date\"].unique())\n",
    "        train_dates = unique_dates[:int(len(unique_dates)*(1-test_size))]\n",
    "        test_dates = unique_dates[unique_dates.index(train_dates[-1])+1:]\n",
    "        train_df = df[df[\"application_date\"].isin(train_dates)]\n",
    "        test_df = df[df[\"application_date\"].isin(test_dates)]\n",
    "\n",
    "        return train_df, test_df\n",
    "    \n",
    "    raise(ValueError(f\"{method} is not a valid method (time based, random)\"))\n",
    "\n",
    "def preprocess_data(df:pd.DataFrame, mode:str, job_id:str=None, rescale=False, ref_job_id:str=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pre-process data and save preprocessed datasets for later use.\n",
    "    :param df: DataFrame\n",
    "    :param mode: str, 'training' or 'inference'\n",
    "    :param job_id: str, job_id for the preprocessed dataset\n",
    "    :param rescale: bool, whether to rescale data.\n",
    "    :param ref_job_id: str, job_id of the last deployed model. Usefull when doing inference.\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    assert mode in ('training', 'inference')\n",
    "    \n",
    "    if mode=='training':\n",
    "        assert config.TARGET in df.columns, f\"{config.TARGET} not in {df.columns}\"\n",
    "\n",
    "    df.columns = list(map(str.lower, df.columns))\n",
    "    initial_size = df.shape[0]\n",
    "    df = df[df[\"customer_id\"].notnull() & df[\"loan_id\"].notnull() & df[\"loan_status\"].notnull()]\n",
    "    if mode=='training':\n",
    "        df[\"loan_status\"] = df[\"loan_status\"].str.lower()\n",
    "    if df.shape[0] != initial_size:\n",
    "        print(f\"[WARNING] Dropped {initial_size - df.shape[0]} rows with null values in (customer_id, loan_id, loan_status)\")\n",
    "    \n",
    "    df = enforce_datatypes(df, cat_vars=cat_vars, num_vars=num_vars)\n",
    "    \n",
    "    df = engineer_features(df)\n",
    "    \n",
    "    if mode=='training':\n",
    "        # split train and test data before encoding categorical variables and imputing missing values\n",
    "        train_df, test_df = split_train_test(df, config.TEST_SPLIT_SIZE, method=config.SPLIT_METHOD)\n",
    "        train_df = encode_categorical_variables(train_df, mode=\"training\", purpose_encode_method=config.PURPOSE_ENCODING_METHOD, job_id=job_id)\n",
    "        train_df = impute_missing_values(train_df, method=\"basic\", mode=\"training\", job_id=job_id)\n",
    "        if rescale:\n",
    "            train_df = rescale_data(train_df, method=config.RESCALE_METHOD, mode=\"training\", columns=num_vars + engineered_vars[\"numerical\"])\n",
    "        helpers.save_dataset(train_df, os.path.join(config.PATH_DIR_DATA, \"preprocessed\", f\"{job_id}_training.csv\"))\n",
    "        preprocess_data(test_df, mode=\"inference\", job_id=job_id, ref_job_id=job_id)\n",
    "    else:\n",
    "        # if mode is infer, no need to split train and test data\n",
    "        test_df = encode_categorical_variables(df, mode=\"inference\", purpose_encode_method=config.PURPOSE_ENCODING_METHOD, job_id=ref_job_id)\n",
    "        test_df = impute_missing_values(test_df, method=\"basic\", mode=\"inference\", job_id=ref_job_id)\n",
    "        if rescale:\n",
    "            test_df = rescale_data(test_df, method=config.RESCALE_METHOD, mode=\"inference\", columns=num_vars + engineered_vars[\"numerical\"])\n",
    "        helpers.save_dataset(test_df, os.path.join(config.PATH_DIR_DATA, \"preprocessed\", f\"{job_id}_inference.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yassine\\AppData\\Local\\Temp\\ipykernel_13324\\3106307468.py:308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].str.lower()\n",
      "C:\\Users\\Yassine\\AppData\\Local\\Temp\\ipykernel_13324\\3106307468.py:310: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"term\"] = df[\"term\"].apply(lambda x: term_to_int(x))\n",
      "C:\\Users\\Yassine\\AppData\\Local\\Temp\\ipykernel_13324\\3106307468.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"home_ownership\"] = df[\"home_ownership\"].apply(lambda x: home_ownership_to_int(x))\n",
      "C:\\Users\\Yassine\\AppData\\Local\\Temp\\ipykernel_13324\\3106307468.py:312: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"years_in_current_job\"] = df[\"years_in_current_job\"].apply(lambda x: categorize_years_in_current_job(x))\n",
      "C:\\Users\\Yassine\\AppData\\Local\\Temp\\ipykernel_13324\\3106307468.py:314: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[config.TARGET.lower()] = df[config.TARGET.lower()].apply(lambda x: loan_status_to_int(x))\n",
      "C:\\Users\\Yassine\\AppData\\Local\\Temp\\ipykernel_13324\\3106307468.py:315: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"purpose\"] = purpose_to_int(df[\"purpose\"], mode=mode, method=purpose_encode_method, job_id=job_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Converting purpose to int using method: weighted ranking\n",
      "[INFO] No model for purpose-to-int conversion provided. Training a new model first...\n",
      "[INFO] Model saved as json file: ../dags/models\\04782775f4d4426f8b5256546c1e2960_purpose_to_int_model.json\n",
      "[INFO] Treating missing values in column: loan_id\n",
      "[INFO] Treating missing values in column: customer_id\n",
      "[INFO] Treating missing values in column: loan_status\n",
      "[INFO] Treating missing values in column: application_time\n",
      "[INFO] Treating missing values in column: current_loan_amount\n",
      "[INFO] Treating missing values in column: term\n",
      "[INFO] Treating missing values in column: tax_liens\n",
      "[INFO] Treating missing values in column: purpose\n",
      "[INFO] Treating missing values in column: no_of_properties\n",
      "[INFO] Treating missing values in column: home_ownership\n",
      "[INFO] Treating missing values in column: annual_income\n",
      "[INFO] Treating missing values in column: years_in_current_job\n",
      "[INFO] Treating missing values in column: months_since_last_delinquent\n",
      "[INFO] Treating missing values in column: no_of_cars\n",
      "[INFO] Treating missing values in column: no_of_children\n",
      "[INFO] Treating missing values in column: credit_score\n",
      "[INFO] Treating missing values in column: monthly_debt\n",
      "[INFO] Treating missing values in column: years_of_credit_history\n",
      "[INFO] Treating missing values in column: no_of_open_accounts\n",
      "[INFO] Treating missing values in column: no_of_credit_problems\n",
      "[INFO] Treating missing values in column: current_credit_balance\n",
      "[INFO] Treating missing values in column: max_open_credit\n",
      "[INFO] Treating missing values in column: bankruptcies\n",
      "[INFO] Treating missing values in column: application_date\n",
      "[INFO] Treating missing values in column: application_year\n",
      "[INFO] Treating missing values in column: application_month\n",
      "[INFO] Treating missing values in column: application_week\n",
      "[INFO] Treating missing values in column: application_day\n",
      "[INFO] Treating missing values in column: application_season\n",
      "[INFO] Treating missing values in column: current_credit_balance_ratio\n",
      "[INFO] Model saved as pickle file: ../dags/models\\04782775f4d4426f8b5256546c1e2960_missing_values_model.pkl\n",
      "[INFO] Model loaded: 04782775f4d4426f8b5256546c1e2960_missing_values_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yassine\\AppData\\Local\\Temp\\ipykernel_13324\\3106307468.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col].fillna(model[\"imputes\"][col]['mean'], inplace=True)\n",
      "C:\\Users\\Yassine\\AppData\\Local\\Temp\\ipykernel_13324\\3106307468.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col].fillna(model[\"imputes\"][col]['mode'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset saved to ../dags/data\\preprocessed\\04782775f4d4426f8b5256546c1e2960_training.csv\n",
      "[INFO] Converting purpose to int using method: weighted ranking\n",
      "[INFO] No model for purpose-to-int conversion provided. Training a new model first...\n",
      "[INFO] Model saved as json file: ../dags/models\\04782775f4d4426f8b5256546c1e2960_purpose_to_int_model.json\n",
      "[INFO] Model loaded: 04782775f4d4426f8b5256546c1e2960_missing_values_model\n",
      "[INFO] Dataset saved to ../dags/data\\preprocessed\\04782775f4d4426f8b5256546c1e2960_inference.csv\n"
     ]
    }
   ],
   "source": [
    "job_id = \"04782775f4d4426f8b5256546c1e2960\"\n",
    "\n",
    "\n",
    "#change this filename and job id accordingly\n",
    "filename = f\"../dags/data/collected/{job_id}.csv\"\n",
    "df = helpers.load_dataset(os.path.join(filename))\n",
    "_ = preprocess_data(df=df, mode=\"training\", job_id=job_id, rescale=False, ref_job_id=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv(f\"../dags/data/preprocessed/{job_id}_training.csv\")\n",
    "inference_df = pd.read_csv(f\"../dags/data/preprocessed/{job_id}_inference.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>current_loan_amount</th>\n",
       "      <td>33231.000000</td>\n",
       "      <td>15612.000000</td>\n",
       "      <td>7959.000000</td>\n",
       "      <td>29346.000000</td>\n",
       "      <td>6011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_score</th>\n",
       "      <td>1350.696132</td>\n",
       "      <td>1350.696132</td>\n",
       "      <td>1350.696132</td>\n",
       "      <td>1350.696132</td>\n",
       "      <td>1350.696132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years_in_current_job</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_ownership</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>71612.920399</td>\n",
       "      <td>71612.920399</td>\n",
       "      <td>71612.920399</td>\n",
       "      <td>71612.920399</td>\n",
       "      <td>71612.920399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose</th>\n",
       "      <td>0.786098</td>\n",
       "      <td>0.060076</td>\n",
       "      <td>0.060076</td>\n",
       "      <td>0.786098</td>\n",
       "      <td>0.003407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_debt</th>\n",
       "      <td>941.224573</td>\n",
       "      <td>941.224573</td>\n",
       "      <td>949.300000</td>\n",
       "      <td>941.224573</td>\n",
       "      <td>941.224573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years_of_credit_history</th>\n",
       "      <td>18.560949</td>\n",
       "      <td>18.560949</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.560949</td>\n",
       "      <td>18.560949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>months_since_last_delinquent</th>\n",
       "      <td>34.752726</td>\n",
       "      <td>34.752726</td>\n",
       "      <td>34.752726</td>\n",
       "      <td>34.752726</td>\n",
       "      <td>34.752726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_open_accounts</th>\n",
       "      <td>11.028741</td>\n",
       "      <td>11.028741</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.028741</td>\n",
       "      <td>11.028741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_credit_problems</th>\n",
       "      <td>0.145312</td>\n",
       "      <td>0.145312</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.145312</td>\n",
       "      <td>0.145312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_credit_balance</th>\n",
       "      <td>15439.198372</td>\n",
       "      <td>15439.198372</td>\n",
       "      <td>4993.000000</td>\n",
       "      <td>15439.198372</td>\n",
       "      <td>15439.198372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_open_credit</th>\n",
       "      <td>40776.357186</td>\n",
       "      <td>40776.357186</td>\n",
       "      <td>14729.000000</td>\n",
       "      <td>40776.357186</td>\n",
       "      <td>40776.357186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bankruptcies</th>\n",
       "      <td>0.105735</td>\n",
       "      <td>0.105735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105735</td>\n",
       "      <td>0.105735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tax_liens</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_properties</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_cars</th>\n",
       "      <td>2.490606</td>\n",
       "      <td>2.490606</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.490606</td>\n",
       "      <td>2.490606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_children</th>\n",
       "      <td>1.501658</td>\n",
       "      <td>1.501658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.501658</td>\n",
       "      <td>1.501658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_year</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_month</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_week</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_day</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_season</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_credit_balance_ratio</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_status</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         0             1             2  \\\n",
       "current_loan_amount           33231.000000  15612.000000   7959.000000   \n",
       "term                              0.000000      1.000000      0.000000   \n",
       "credit_score                   1350.696132   1350.696132   1350.696132   \n",
       "years_in_current_job             -1.000000     -1.000000      2.000000   \n",
       "home_ownership                    1.000000      1.000000      1.000000   \n",
       "annual_income                 71612.920399  71612.920399  71612.920399   \n",
       "purpose                           0.786098      0.060076      0.060076   \n",
       "monthly_debt                    941.224573    941.224573    949.300000   \n",
       "years_of_credit_history          18.560949     18.560949     21.000000   \n",
       "months_since_last_delinquent     34.752726     34.752726     34.752726   \n",
       "no_of_open_accounts              11.028741     11.028741     12.000000   \n",
       "no_of_credit_problems             0.145312      0.145312      1.000000   \n",
       "current_credit_balance        15439.198372  15439.198372   4993.000000   \n",
       "max_open_credit               40776.357186  40776.357186  14729.000000   \n",
       "bankruptcies                      0.105735      0.105735      1.000000   \n",
       "tax_liens                         0.000000      0.000000      0.000000   \n",
       "no_of_properties                  1.000000      2.000000      2.000000   \n",
       "no_of_cars                        2.490606      2.490606      4.000000   \n",
       "no_of_children                    1.501658      1.501658      0.000000   \n",
       "application_year               2015.000000   2015.000000   2015.000000   \n",
       "application_month                 1.000000      4.000000      2.000000   \n",
       "application_week                  2.000000     15.000000      7.000000   \n",
       "application_day                   6.000000      8.000000     10.000000   \n",
       "application_season                1.000000      2.000000      1.000000   \n",
       "current_credit_balance_ratio      0.000000      0.000000      0.627340   \n",
       "loan_status                       1.000000      1.000000      0.000000   \n",
       "\n",
       "                                         3             4  \n",
       "current_loan_amount           29346.000000   6011.000000  \n",
       "term                              1.000000      0.000000  \n",
       "credit_score                   1350.696132   1350.696132  \n",
       "years_in_current_job             -1.000000     -1.000000  \n",
       "home_ownership                    1.000000      1.000000  \n",
       "annual_income                 71612.920399  71612.920399  \n",
       "purpose                           0.786098      0.003407  \n",
       "monthly_debt                    941.224573    941.224573  \n",
       "years_of_credit_history          18.560949     18.560949  \n",
       "months_since_last_delinquent     34.752726     34.752726  \n",
       "no_of_open_accounts              11.028741     11.028741  \n",
       "no_of_credit_problems             0.145312      0.145312  \n",
       "current_credit_balance        15439.198372  15439.198372  \n",
       "max_open_credit               40776.357186  40776.357186  \n",
       "bankruptcies                      0.105735      0.105735  \n",
       "tax_liens                         0.000000      0.000000  \n",
       "no_of_properties                  2.000000      4.000000  \n",
       "no_of_cars                        2.490606      2.490606  \n",
       "no_of_children                    1.501658      1.501658  \n",
       "application_year               2015.000000   2015.000000  \n",
       "application_month                 2.000000      4.000000  \n",
       "application_week                  7.000000     16.000000  \n",
       "application_day                  10.000000     15.000000  \n",
       "application_season                1.000000      2.000000  \n",
       "current_credit_balance_ratio      0.000000      0.000000  \n",
       "loan_status                       1.000000      1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df[config.PREDICTORS + [config.TARGET]].head().T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
